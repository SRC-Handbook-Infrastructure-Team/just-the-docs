---
layout: sidepanel
sidepanel: true
title: "Failures of Distribution"
nav_exclude: true
---

## Distribution Dimension of Justice

**Violations of sufficiency**
- [ Guardian: “What happened when a ‘wildly irrational’ algorithm made crucial healthcare decisions”](https://www.theguardian.com/us-news/2021/jul/02/algorithm-crucial-healthcare-decisions){:target="_blank"}
- [State of Michigan's mistake led to man filing bankruptcy](https://www.freep.com/story/news/local/michigan/2019/12/22/government-artificial-intelligence-midas-computer-fraud-fiasco/4407901002/){:target="_blank"}
- [Report: Challenging the Use of Algorithm-driven Decision-making in Benefits Determinations Affecting People with Disabilities - Center for Democracy and Technology](https://cdt.org/insights/report-challenging-the-use-of-algorithm-driven-decision-making-in-benefits-determinations-affecting-people-with-disabilities/){:target="_blank"}<!-- tag:case-study -->

**Violations of priority** 
- Tenant scoring systems which make it harder for already socio-economically disadvantaged people to access housing ProPublica: [“Landlords Use Secret Algorithms to Screen Potential Tenants. Find Out What They’ve Said About You.”](https://www.propublica.org/article/landlords-use-secret-algorithms-to-screen-potential-tenants-find-out-what-theyve-said-about-you){:target="_blank"}<!-- tag:case-study -->


**Violations of equality of opportunity:**
- Automated decision system example violating equality of opportunity criterion, e.g., hiring systems which discriminate against women [AI Discrimination in Hiring, and What We Can Do About It](https://www.newamerica.org/oti/blog/ai-discrimination-in-hiring-and-what-we-can-do-about-it/){:target="_blank"}<!-- tag:case-study -->
 
For more comprehensive examples on harms from the institutionalization of AI, see:
- [Race After Technology](https://www.ruhabenjamin.com/race-after-technology){:target="_blank"}

---
layout: page
title: "Appendix"
parent: "2.c.ii - Algorithmic Justice"
appendix: true
---

# Appendix for Learning Objective 2.c.ii - Algorithmic Justice
These are all the external links mentioned in the body of the text and in the side panels, categorized by type.
### Case Studies
- [Report: Challenging the Use of Algorithm-driven Decision-making in Benefits Determinations Affecting People with Disabilities - Center for Democracy and Technology](https://cdt.org/insights/report-challenging-the-use-of-algorithm-driven-decision-making-in-benefits-determinations-affecting-people-with-disabilities/){:target="_blank"}<!-- tag:case-study --> [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-distribution#:~:text=Report%3A%20Challenging%20the%20Use%20of%20Algorithm-driven%20Decision-making%20in%20Benefits%20Determinations%20Affecting%20People%20with%20Disabilities%20-%20Center%20for%20Democracy%20and%20Technology){: .backlink }
- [“Landlords Use Secret Algorithms to Screen Potential Tenants. Find Out What They’ve Said About You.”](https://www.propublica.org/article/landlords-use-secret-algorithms-to-screen-potential-tenants-find-out-what-theyve-said-about-you){:target="_blank"}<!-- tag:case-study --> [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-distribution#:~:text=%E2%80%9CLandlords%20Use%20Secret%20Algorithms%20to%20Screen%20Potential%20Tenants.%20Find%20Out%20What%20They%E2%80%99ve%20Said%20About%20You.%E2%80%9D){: .backlink }
- [AI Discrimination in Hiring, and What We Can Do About It](https://www.newamerica.org/oti/blog/ai-discrimination-in-hiring-and-what-we-can-do-about-it/){:target="_blank"}<!-- tag:case-study --> [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-distribution#:~:text=AI%20Discrimination%20in%20Hiring%2C%20and%20What%20We%20Can%20Do%20About%20It){: .backlink }

### Uncategorized Links
- [Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness](https://link.springer.com/article/10.1007/s13347-022-00584-6){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=sociopolitical-factors-and-approaches#:~:text=Escaping%20the%20Impossibility%20of%20Fairness%3A%20From%20Formal%20to%20Substantive%20Algorithmic%20Fairness){: .backlink }
- [Anna Lauren Hoffmann: Where fairness fails: data, algorithms, and the limits of antidiscrimination discourse](https://www.tandfonline.com/doi/full/10.1080/1369118X.2019.1573912){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=sociopolitical-factors-and-approaches#:~:text=Anna%20Lauren%20Hoffmann%3A%20Where%20fairness%20fails%3A%20data%2C%20algorithms%2C%20and%20the%20limits%20of%20antidiscrimination%20discourse){: .backlink }
- [Gender bias and stereotypes in Large Language Models](https://dl.acm.org/doi/fullHtml/10.1145/3582269.3615599){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-recognition#:~:text=Gender%20bias%20and%20stereotypes%20in%20Large%20Language%20Models){: .backlink }
- [Generative AI Takes Stereotypes and Bias From Bad to Worse ](https://www.bloomberg.com/graphics/2023-generative-ai-bias/){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-recognition#:~:text=Generative%20AI%20Takes%20Stereotypes%20and%20Bias%20From%20Bad%20to%20Worse%20){: .backlink }
- [Algorithms of Oppression: How Search Engines Reinforce Racism ](https://www.jstor.org/stable/j.ctt1pwt9w5){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-recognition#:~:text=Algorithms%20of%20Oppression%3A%20How%20Search%20Engines%20Reinforce%20Racism%20){: .backlink }
- [Reverse Engineering the Gendered Design of Amazon’s Alexa: Methods in Testing Closed-Source Code in Grey and Black Box Systems](https://digitalhumanities.org/dhq/vol/17/2/000700/000700.html){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-recognition#:~:text=Reverse%20Engineering%20the%20Gendered%20Design%20of%20Amazon%E2%80%99s%20Alexa%3A%20Methods%20in%20Testing%20Closed-Source%20Code%20in%20Grey%20and%20Black%20Box%20Systems){: .backlink }
- [Reducing biased and harmful outcomes in generative AI Design Justice, A.I., and Escape from the Matrix of Domination](https://jods.mitpress.mit.edu/pub/costanza-chock/release/4){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-recognition#:~:text=Reducing%20biased%20and%20harmful%20outcomes%20in%20generative%20AI%20Design%20Justice%2C%20A.I.%2C%20and%20Escape%20from%20the%20Matrix%20of%20Domination){: .backlink }
- [ Guardian: “What happened when a ‘wildly irrational’ algorithm made crucial healthcare decisions”](https://www.theguardian.com/us-news/2021/jul/02/algorithm-crucial-healthcare-decisions){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-distribution#:~:text=%20Guardian%3A%20%E2%80%9CWhat%20happened%20when%20a%20%E2%80%98wildly%20irrational%E2%80%99%20algorithm%20made%20crucial%20healthcare%20decisions%E2%80%9D){: .backlink }
- [State of Michigan's mistake led to man filing bankruptcy](https://www.freep.com/story/news/local/michigan/2019/12/22/government-artificial-intelligence-midas-computer-fraud-fiasco/4407901002/){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-distribution#:~:text=State%20of%20Michigan's%20mistake%20led%20to%20man%20filing%20bankruptcy){: .backlink }
- [Race After Technology](https://www.ruhabenjamin.com/race-after-technology){:target="_blank"} [view in context](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.ii/?panel=failures-of-distribution#:~:text=Race%20After%20Technology){: .backlink }


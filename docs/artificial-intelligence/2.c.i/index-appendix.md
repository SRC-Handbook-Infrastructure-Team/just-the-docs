---
layout: page
title: "Appendix"
parent: "2.c.i - Algorithmic Fairness"
appendix: true
---

# Appendix for Learning Objective 2.c.i - Algorithmic Fairness
These are all the external links mentioned in the body of the text and in the side panels, categorized by type.
### Definitions
- [Minow: Equality vs. Equity](https://direct.mit.edu/ajle/article/doi/10.1162/ajle_a_00019/107229/EQUALITY-VS-EQUITY){:target="_blank"}<!-- tag:definition --> [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=equity-equality#:~:text=Minow%3A%20Equality%20vs.%20Equity){: .backlink }
- [Fairness and Machine Learning](https://fairmlbook.org/){:target="_blank"}<!-- tag:definition --> [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=group-fairness#:~:text=Fairness%20and%20Machine%20Learning){: .backlink }

### Case Studies
- [Social Identities and Systems of Oppression \| National Museum of African American History and Culture](https://nmaahc.si.edu/learn/talking-about-race/topics/social-identities-and-systems-oppression){:target="_blank"}<!-- tag:case-study --> [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=systems-of-oppression#:~:text=Social%20Identities%20and%20Systems%20of%20Oppression%20%5C%7C%20National%20Museum%20of%20African%20American%20History%20and%20Culture){: .backlink }
- [Inherent Trade-Offs in the Fair Determination of Risk Scores](https://arxiv.org/abs/1609.05807){:target="_blank"}<!-- tag:case-study --> [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=impossibility-of-fairness#:~:text=Inherent%20Trade-Offs%20in%20the%20Fair%20Determination%20of%20Risk%20Scores){: .backlink }

### Uncategorized Links
- [Why Is Oppression Wrong? \| Philosophical Studies](https://link.springer.com/article/10.1007/s11098-023-02084-5#Sec2){:target="_blank"} [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=systems-of-oppression#:~:text=Why%20Is%20Oppression%20Wrong%3F%20%5C%7C%20Philosophical%20Studies){: .backlink }
- [Brownâ€™s Race, Power, and Privilege courses](https://college.brown.edu/design-your-education/explore-open-curriculum/course-selection/curricular-programs/examining-race){:target="_blank"} [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=systems-of-oppression#:~:text=Brown%E2%80%99s%20Race%2C%20Power%2C%20and%20Privilege%20courses){: .backlink }
- [The (Im)possibility of fairness: different value systems require different mechanisms for fair decision making](https://dl.acm.org/doi/10.1145/3433949){:target="_blank"} [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=impossibility-of-fairness#:~:text=The%20(Im)possibility%20of%20fairness%3A%20different%20value%20systems%20require%20different%20mechanisms%20for%20fair%20decision%20making){: .backlink }
- [Fair prediction with disparate impact](https://arxiv.org/pdf/1703.00056){:target="_blank"} [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=impossibility-of-fairness#:~:text=Fair%20prediction%20with%20disparate%20impact){: .backlink }
- [Algorithmic decision making and the cost of fairness](https://arxiv.org/pdf/1701.08230){:target="_blank"} [[view in context]](https:/src-handbook-infrastructure-team.github.io/srch/docs/artificial-intelligence/2.c.i/?panel=impossibility-of-fairness#:~:text=Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness){: .backlink }

